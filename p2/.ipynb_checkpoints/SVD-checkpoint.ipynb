{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "26fa4b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train MAE: 0.8800, Train RMSE: 1.0836, Train MSE: 1.1742, Val MAE: 0.8315, Val RMSE: 1.0301, Val MSE: 1.0610\n",
      "Epoch: 2, Train MAE: 0.8060, Train RMSE: 1.0052, Train MSE: 1.0105, Val MAE: 0.7878, Val RMSE: 0.9836, Val MSE: 0.9675\n",
      "Epoch: 3, Train MAE: 0.7724, Train RMSE: 0.9681, Train MSE: 0.9371, Val MAE: 0.7610, Val RMSE: 0.9538, Val MSE: 0.9097\n",
      "Epoch: 4, Train MAE: 0.7500, Train RMSE: 0.9423, Train MSE: 0.8880, Val MAE: 0.7412, Val RMSE: 0.9315, Val MSE: 0.8677\n",
      "Epoch: 5, Train MAE: 0.7330, Train RMSE: 0.9224, Train MSE: 0.8508, Val MAE: 0.7255, Val RMSE: 0.9137, Val MSE: 0.8349\n",
      "Epoch: 6, Train MAE: 0.7192, Train RMSE: 0.9060, Train MSE: 0.8208, Val MAE: 0.7125, Val RMSE: 0.8988, Val MSE: 0.8079\n",
      "Epoch: 7, Train MAE: 0.7076, Train RMSE: 0.8919, Train MSE: 0.7955, Val MAE: 0.7016, Val RMSE: 0.8860, Val MSE: 0.7851\n",
      "Epoch: 8, Train MAE: 0.6975, Train RMSE: 0.8797, Train MSE: 0.7738, Val MAE: 0.6921, Val RMSE: 0.8749, Val MSE: 0.7654\n",
      "Epoch: 9, Train MAE: 0.6887, Train RMSE: 0.8688, Train MSE: 0.7548, Val MAE: 0.6837, Val RMSE: 0.8650, Val MSE: 0.7482\n",
      "Epoch: 10, Train MAE: 0.6809, Train RMSE: 0.8591, Train MSE: 0.7380, Val MAE: 0.6764, Val RMSE: 0.8562, Val MSE: 0.7330\n",
      "Epoch: 11, Train MAE: 0.6738, Train RMSE: 0.8504, Train MSE: 0.7231, Val MAE: 0.6698, Val RMSE: 0.8483, Val MSE: 0.7196\n",
      "Epoch: 12, Train MAE: 0.6675, Train RMSE: 0.8425, Train MSE: 0.7098, Val MAE: 0.6639, Val RMSE: 0.8412, Val MSE: 0.7076\n",
      "Epoch: 13, Train MAE: 0.6618, Train RMSE: 0.8354, Train MSE: 0.6978, Val MAE: 0.6585, Val RMSE: 0.8348, Val MSE: 0.6969\n",
      "Epoch: 14, Train MAE: 0.6567, Train RMSE: 0.8289, Train MSE: 0.6871, Val MAE: 0.6538, Val RMSE: 0.8291, Val MSE: 0.6874\n",
      "Epoch: 15, Train MAE: 0.6520, Train RMSE: 0.8231, Train MSE: 0.6775, Val MAE: 0.6495, Val RMSE: 0.8239, Val MSE: 0.6788\n",
      "Epoch: 16, Train MAE: 0.6478, Train RMSE: 0.8179, Train MSE: 0.6689, Val MAE: 0.6457, Val RMSE: 0.8193, Val MSE: 0.6712\n",
      "Epoch: 17, Train MAE: 0.6440, Train RMSE: 0.8131, Train MSE: 0.6611, Val MAE: 0.6423, Val RMSE: 0.8151, Val MSE: 0.6643\n",
      "Epoch: 18, Train MAE: 0.6406, Train RMSE: 0.8088, Train MSE: 0.6542, Val MAE: 0.6392, Val RMSE: 0.8113, Val MSE: 0.6582\n",
      "Epoch: 19, Train MAE: 0.6375, Train RMSE: 0.8049, Train MSE: 0.6479, Val MAE: 0.6364, Val RMSE: 0.8079, Val MSE: 0.6527\n",
      "Epoch: 20, Train MAE: 0.6347, Train RMSE: 0.8015, Train MSE: 0.6423, Val MAE: 0.6339, Val RMSE: 0.8048, Val MSE: 0.6478\n",
      "Epoch: 21, Train MAE: 0.6322, Train RMSE: 0.7983, Train MSE: 0.6373, Val MAE: 0.6316, Val RMSE: 0.8021, Val MSE: 0.6433\n",
      "Epoch: 22, Train MAE: 0.6299, Train RMSE: 0.7955, Train MSE: 0.6328, Val MAE: 0.6296, Val RMSE: 0.7996, Val MSE: 0.6393\n",
      "Epoch: 23, Train MAE: 0.6279, Train RMSE: 0.7929, Train MSE: 0.6287, Val MAE: 0.6278, Val RMSE: 0.7974, Val MSE: 0.6358\n",
      "Epoch: 24, Train MAE: 0.6261, Train RMSE: 0.7906, Train MSE: 0.6250, Val MAE: 0.6262, Val RMSE: 0.7953, Val MSE: 0.6326\n",
      "Epoch: 25, Train MAE: 0.6244, Train RMSE: 0.7885, Train MSE: 0.6217, Val MAE: 0.6247, Val RMSE: 0.7935, Val MSE: 0.6297\n",
      "Epoch: 26, Train MAE: 0.6229, Train RMSE: 0.7866, Train MSE: 0.6188, Val MAE: 0.6233, Val RMSE: 0.7919, Val MSE: 0.6271\n",
      "Epoch: 27, Train MAE: 0.6216, Train RMSE: 0.7849, Train MSE: 0.6161, Val MAE: 0.6222, Val RMSE: 0.7904, Val MSE: 0.6248\n",
      "Epoch: 28, Train MAE: 0.6203, Train RMSE: 0.7834, Train MSE: 0.6137, Val MAE: 0.6211, Val RMSE: 0.7891, Val MSE: 0.6227\n",
      "Epoch: 29, Train MAE: 0.6192, Train RMSE: 0.7820, Train MSE: 0.6116, Val MAE: 0.6201, Val RMSE: 0.7879, Val MSE: 0.6208\n",
      "Epoch: 30, Train MAE: 0.6183, Train RMSE: 0.7808, Train MSE: 0.6097, Val MAE: 0.6192, Val RMSE: 0.7868, Val MSE: 0.6191\n",
      "Epoch: 31, Train MAE: 0.6174, Train RMSE: 0.7797, Train MSE: 0.6079, Val MAE: 0.6185, Val RMSE: 0.7859, Val MSE: 0.6176\n",
      "Epoch: 32, Train MAE: 0.6166, Train RMSE: 0.7787, Train MSE: 0.6064, Val MAE: 0.6178, Val RMSE: 0.7850, Val MSE: 0.6162\n",
      "Epoch: 33, Train MAE: 0.6159, Train RMSE: 0.7778, Train MSE: 0.6050, Val MAE: 0.6171, Val RMSE: 0.7842, Val MSE: 0.6150\n",
      "Epoch: 34, Train MAE: 0.6152, Train RMSE: 0.7770, Train MSE: 0.6037, Val MAE: 0.6166, Val RMSE: 0.7835, Val MSE: 0.6139\n",
      "Epoch: 35, Train MAE: 0.6146, Train RMSE: 0.7763, Train MSE: 0.6026, Val MAE: 0.6160, Val RMSE: 0.7829, Val MSE: 0.6129\n",
      "Epoch: 36, Train MAE: 0.6141, Train RMSE: 0.7756, Train MSE: 0.6015, Val MAE: 0.6156, Val RMSE: 0.7823, Val MSE: 0.6120\n",
      "Epoch: 37, Train MAE: 0.6136, Train RMSE: 0.7750, Train MSE: 0.6006, Val MAE: 0.6152, Val RMSE: 0.7818, Val MSE: 0.6112\n",
      "Epoch: 38, Train MAE: 0.6132, Train RMSE: 0.7745, Train MSE: 0.5998, Val MAE: 0.6148, Val RMSE: 0.7813, Val MSE: 0.6105\n",
      "Epoch: 39, Train MAE: 0.6128, Train RMSE: 0.7740, Train MSE: 0.5991, Val MAE: 0.6145, Val RMSE: 0.7809, Val MSE: 0.6099\n",
      "Epoch: 40, Train MAE: 0.6125, Train RMSE: 0.7736, Train MSE: 0.5984, Val MAE: 0.6142, Val RMSE: 0.7806, Val MSE: 0.6093\n",
      "Epoch: 41, Train MAE: 0.6122, Train RMSE: 0.7732, Train MSE: 0.5978, Val MAE: 0.6139, Val RMSE: 0.7802, Val MSE: 0.6087\n",
      "Epoch: 42, Train MAE: 0.6119, Train RMSE: 0.7728, Train MSE: 0.5972, Val MAE: 0.6136, Val RMSE: 0.7799, Val MSE: 0.6083\n",
      "Epoch: 43, Train MAE: 0.6117, Train RMSE: 0.7725, Train MSE: 0.5968, Val MAE: 0.6134, Val RMSE: 0.7796, Val MSE: 0.6078\n",
      "Epoch: 44, Train MAE: 0.6114, Train RMSE: 0.7722, Train MSE: 0.5963, Val MAE: 0.6132, Val RMSE: 0.7794, Val MSE: 0.6075\n",
      "Epoch: 45, Train MAE: 0.6112, Train RMSE: 0.7720, Train MSE: 0.5959, Val MAE: 0.6130, Val RMSE: 0.7792, Val MSE: 0.6071\n",
      "Epoch: 46, Train MAE: 0.6110, Train RMSE: 0.7717, Train MSE: 0.5956, Val MAE: 0.6129, Val RMSE: 0.7790, Val MSE: 0.6068\n",
      "Epoch: 47, Train MAE: 0.6109, Train RMSE: 0.7715, Train MSE: 0.5953, Val MAE: 0.6127, Val RMSE: 0.7788, Val MSE: 0.6065\n",
      "Epoch: 48, Train MAE: 0.6107, Train RMSE: 0.7713, Train MSE: 0.5950, Val MAE: 0.6126, Val RMSE: 0.7786, Val MSE: 0.6063\n",
      "Epoch: 49, Train MAE: 0.6106, Train RMSE: 0.7712, Train MSE: 0.5947, Val MAE: 0.6125, Val RMSE: 0.7785, Val MSE: 0.6061\n",
      "Epoch: 50, Train MAE: 0.6105, Train RMSE: 0.7710, Train MSE: 0.5945, Val MAE: 0.6124, Val RMSE: 0.7784, Val MSE: 0.6059\n",
      "Epoch: 51, Train MAE: 0.6104, Train RMSE: 0.7709, Train MSE: 0.5943, Val MAE: 0.6123, Val RMSE: 0.7782, Val MSE: 0.6057\n",
      "Epoch: 52, Train MAE: 0.6103, Train RMSE: 0.7708, Train MSE: 0.5941, Val MAE: 0.6122, Val RMSE: 0.7781, Val MSE: 0.6055\n",
      "Epoch: 53, Train MAE: 0.6102, Train RMSE: 0.7707, Train MSE: 0.5939, Val MAE: 0.6121, Val RMSE: 0.7780, Val MSE: 0.6054\n",
      "Epoch: 54, Train MAE: 0.6101, Train RMSE: 0.7706, Train MSE: 0.5938, Val MAE: 0.6120, Val RMSE: 0.7780, Val MSE: 0.6052\n",
      "Epoch: 55, Train MAE: 0.6100, Train RMSE: 0.7705, Train MSE: 0.5936, Val MAE: 0.6120, Val RMSE: 0.7779, Val MSE: 0.6051\n",
      "Epoch: 56, Train MAE: 0.6100, Train RMSE: 0.7704, Train MSE: 0.5935, Val MAE: 0.6119, Val RMSE: 0.7778, Val MSE: 0.6050\n",
      "Epoch: 57, Train MAE: 0.6099, Train RMSE: 0.7703, Train MSE: 0.5934, Val MAE: 0.6119, Val RMSE: 0.7778, Val MSE: 0.6049\n",
      "Epoch: 58, Train MAE: 0.6099, Train RMSE: 0.7702, Train MSE: 0.5933, Val MAE: 0.6118, Val RMSE: 0.7777, Val MSE: 0.6048\n",
      "Early stopping after 58 epochs\n"
     ]
    }
   ],
   "source": [
    "# Title:  CSEN272 Project 2 \n",
    "# Author: Yanxu Wu (W1650780)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Change test files for different results\n",
    "train_file = 'train_test_file/train.txt'\n",
    "test_file = 'train_test_file/test20.txt'\n",
    "\n",
    "# Load the training data\n",
    "train_data = pd.read_csv(train_file, sep=' ', header=None, names=['user', 'movie', 'rating'])\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv(test_file, sep=' ', header=None, names=['user', 'movie', 'rating'])\n",
    "\n",
    "# Add known ratings from the test data to the training data\n",
    "known_test_data = test_data[test_data['rating'] != 0]\n",
    "combined_data = pd.concat([train_data, known_test_data])\n",
    "\n",
    "# Split the combined data into training and validation sets\n",
    "train_set, val_set = train_test_split(combined_data, test_size=0.2, random_state=42)\n",
    "\n",
    "#print(val_set)\n",
    "\n",
    "# Get the number of users and movies dimensions\n",
    "n_users = max(combined_data['user'].max(), test_data['user'].max()) + 1\n",
    "n_items = max(combined_data['movie'].max(), test_data['movie'].max()) + 1\n",
    "\n",
    "# refiend SVD Model\n",
    "class SVD:\n",
    "    def __init__(self, n_epochs, n_users, n_items, n_factors, lr, reg_rate, random_seed=0):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.reg_rate = reg_rate\n",
    "        self.n_factors = n_factors\n",
    "        np.random.seed(random_seed)\n",
    "        self.pu = np.random.randn(n_users, n_factors) / np.sqrt(n_factors)\n",
    "        self.qi = np.random.randn(n_items, n_factors) / np.sqrt(n_factors)\n",
    "        self.yj = np.random.randn(n_items, n_factors) / np.sqrt(n_factors)\n",
    "        self.bu = np.zeros(n_users, np.double)\n",
    "        self.bi = np.zeros(n_items, np.double)\n",
    "        self.global_bias = 0\n",
    "        self.Iu = {u: [] for u in range(n_users)}\n",
    "        \n",
    "    def reg_sum_yj(self, u):\n",
    "        sum_yj = np.zeros(self.n_factors, np.double)\n",
    "        for j in self.Iu[u]:\n",
    "            sum_yj += self.yj[j]\n",
    "        return sum_yj / np.sqrt(len(self.Iu[u])) if self.Iu[u] else sum_yj\n",
    "        \n",
    "    def predict(self, u, i, feedback):\n",
    "        return self.global_bias + self.bu[u] + self.bi[i] + np.dot(self.qi[i], self.pu[u] + feedback)\n",
    "        \n",
    "    def fit(self, train_set, val_set, verbose=True, patience=2, min_delta=0.0001):\n",
    "        self.global_bias = np.mean(train_set.rating)\n",
    "        # Record the items rated by each user\n",
    "        group = train_set.groupby(['user'])\n",
    "        for uid, df_uid in group:\n",
    "            self.Iu[uid] = list(df_uid['movie'])\n",
    "            \n",
    "        # record the mae performance after each iteration\n",
    "        best_val_mae = float('inf')\n",
    "        epochs_no_improve = 0\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            total_error = 0\n",
    "            squared_error = 0\n",
    "            \n",
    "            for index, row in train_set.iterrows():\n",
    "                u, i, r = int(row['user']), int(row['movie']), row['rating']\n",
    "                feedback = self.reg_sum_yj(u)\n",
    "                error = r - self.predict(u, i, feedback)\n",
    "                total_error += abs(error)\n",
    "                squared_error += error ** 2\n",
    "                self.bu[u] += self.lr * (error - self.reg_rate * self.bu[u])\n",
    "                self.bi[i] += self.lr * (error - self.reg_rate * self.bi[i])\n",
    "                tmp_pu = self.pu[u]\n",
    "                tmp_qi = self.qi[i]\n",
    "                self.pu[u] += self.lr * (error * self.qi[i] - self.reg_rate * self.pu[u])\n",
    "                self.qi[i] += self.lr * (error * (tmp_pu + feedback) - self.reg_rate * self.qi[i])\n",
    "                \n",
    "                for j in self.Iu[u]:\n",
    "                    self.yj[j] += self.lr * (error / np.sqrt(len(self.Iu[u])) * tmp_qi - self.reg_rate * self.yj[j])\n",
    "            \n",
    "            train_mae = total_error / len(train_set)\n",
    "            train_mse = squared_error / len(train_set)\n",
    "            train_rmse = np.sqrt(train_mse)\n",
    "            val_mae, val_mse, val_rmse = self.evaluate(val_set)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'Epoch: {epoch+1}, Train MAE: {train_mae:.4f}, Train RMSE: {train_rmse:.4f}, Train MSE: {train_mse:.4f}, Val MAE: {val_mae:.4f}, Val RMSE: {val_rmse:.4f}, Val MSE: {val_mse:.4f}')\n",
    "            \n",
    "            # Check for improvement\n",
    "            if best_val_mae - val_mae > min_delta:\n",
    "                best_val_mae = val_mae\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                \n",
    "            # Early stopping\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f'Early stopping after {epoch+1} epochs')\n",
    "                break\n",
    "            \n",
    "            # Reduce learning rate after each epoch\n",
    "            self.lr *= 0.9\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def evaluate(self, test_set):\n",
    "        predictions = test_set.apply(lambda x: self.predict(int(x['user']), int(x['movie']), self.reg_sum_yj(int(x['user']))), axis=1)\n",
    "        mae = np.mean(np.abs(test_set['rating'] - predictions))\n",
    "        mse = mean_squared_error(test_set['rating'], predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return mae, mse, rmse\n",
    "    \n",
    "    def predict_single(self, user, movie):\n",
    "        return self.predict(user, movie, self.reg_sum_yj(user))\n",
    "\n",
    "# Best hyperparameter settings found using gridsearch\n",
    "best_params = {\n",
    "    'n_epochs': 65,\n",
    "    'n_factors': 30,\n",
    "    'lr': 0.01, \n",
    "    'reg_rate': 0.02\n",
    "}\n",
    "\n",
    "# Train the best model on the full training data\n",
    "svd_best = SVD(\n",
    "    n_epochs=best_params['n_epochs'],\n",
    "    n_users=n_users,\n",
    "    n_items=n_items,\n",
    "    n_factors=best_params['n_factors'],\n",
    "    lr=best_params['lr'],\n",
    "    reg_rate=best_params['reg_rate']\n",
    ")\n",
    "\n",
    "svd_best.fit(combined_data, val_set, verbose=True, patience=2, min_delta=0.0001)\n",
    "\n",
    "# Predict a single rating from train data for testing purpose\n",
    "#predicted_single_rating = svd_best.predict_single(69, 129)\n",
    "#print(predicted_single_rating)\n",
    "\n",
    "# Prepare to generate predictions for unknown ratings\n",
    "result = []\n",
    "\n",
    "# Iterate over each user block in the test data\n",
    "for user in range(401, 501):  # Adjust user range based on the test file (e.g. (301, 401) for test10.txt)\n",
    "    user_test_data = test_data[test_data['user'] == user]\n",
    "    unknown_ratings = user_test_data[user_test_data['rating'] == 0]\n",
    "\n",
    "    if len(unknown_ratings) > 0:\n",
    "        # Predict the unknown ratings\n",
    "        for index, row in unknown_ratings.iterrows():\n",
    "            u, m = int(row['user']), int(row['movie'])\n",
    "            predicted_rating = int(round(svd_best.predict_single(u, m)))\n",
    "            predicted_rating = min(max(predicted_rating, 1), 5)\n",
    "            result.append((u, m, predicted_rating))\n",
    "\n",
    "# Convert the result list to a DataFrame and sort it\n",
    "result_df = pd.DataFrame(result, columns=['user', 'movie', 'rating'])\n",
    "result_df.sort_values(by=['user', 'movie'], inplace=True)\n",
    "\n",
    "# Save the predictions (change to result10.txt for test10.txt)\n",
    "result_df.to_csv('result20.txt', sep=' ', header=False, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64203945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
